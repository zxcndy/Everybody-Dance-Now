{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDatasetDataLoader\n",
      "dataset [AlignedDataset] was created\n",
      "#training images = 124\n",
      "pix\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(18, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (20): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (21): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (22): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (23): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (24): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (30): ReLU(inplace)\n",
      "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (33): ReLU(inplace)\n",
      "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (36): ReLU(inplace)\n",
      "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (39): Tanh()\n",
      "  )\n",
      ")\n",
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(21, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(21, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create web directory ./checkpoints/target/web...\n",
      "End of epoch 121 / 200 \t Time Taken: 215 sec\n",
      "End of epoch 122 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 123 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 124 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 125 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 126, iters: 20, time: 1.582) G_GAN: 0.647 G_GAN_Feat: 3.516 G_VGG: 3.333 D_real: 0.375 D_fake: 0.476 \n",
      "saving the latest model (epoch 126, total_steps 15520)\n",
      "End of epoch 126 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 127 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 128 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 129 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 130 / 200 \t Time Taken: 197 sec\n",
      "saving the model at the end of epoch 130, iters 16120\n",
      "(epoch: 131, iters: 40, time: 1.577) G_GAN: 0.794 G_GAN_Feat: 2.525 G_VGG: 2.526 D_real: 0.530 D_fake: 0.340 \n",
      "saving the latest model (epoch 131, total_steps 16160)\n",
      "End of epoch 131 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 132 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 133 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 134 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 135 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 136, iters: 60, time: 1.622) G_GAN: 0.526 G_GAN_Feat: 2.060 G_VGG: 2.665 D_real: 0.407 D_fake: 0.653 \n",
      "saving the latest model (epoch 136, total_steps 16800)\n",
      "End of epoch 136 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 137 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 138 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 139 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 140 / 200 \t Time Taken: 197 sec\n",
      "saving the model at the end of epoch 140, iters 17360\n",
      "(epoch: 141, iters: 80, time: 1.586) G_GAN: 0.686 G_GAN_Feat: 2.145 G_VGG: 2.648 D_real: 0.500 D_fake: 0.394 \n",
      "saving the latest model (epoch 141, total_steps 17440)\n",
      "End of epoch 141 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 142 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 143 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 144 / 200 \t Time Taken: 264 sec\n",
      "End of epoch 145 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 146, iters: 100, time: 1.582) G_GAN: 0.577 G_GAN_Feat: 1.766 G_VGG: 2.253 D_real: 0.503 D_fake: 0.478 \n",
      "saving the latest model (epoch 146, total_steps 18080)\n",
      "End of epoch 146 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 147 / 200 \t Time Taken: 196 sec\n",
      "End of epoch 148 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 149 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 150 / 200 \t Time Taken: 197 sec\n",
      "saving the model at the end of epoch 150, iters 18600\n",
      "(epoch: 151, iters: 120, time: 1.573) G_GAN: 0.427 G_GAN_Feat: 2.034 G_VGG: 2.202 D_real: 0.361 D_fake: 0.659 \n",
      "saving the latest model (epoch 151, total_steps 18720)\n",
      "End of epoch 151 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 152 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 153 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 154 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 155 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 156 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 157, iters: 16, time: 1.634) G_GAN: 0.481 G_GAN_Feat: 2.635 G_VGG: 2.082 D_real: 0.411 D_fake: 0.620 \n",
      "saving the latest model (epoch 157, total_steps 19360)\n",
      "End of epoch 157 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 158 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 159 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 160 / 200 \t Time Taken: 197 sec\n",
      "saving the model at the end of epoch 160, iters 19840\n",
      "End of epoch 161 / 200 \t Time Taken: 196 sec\n",
      "(epoch: 162, iters: 36, time: 1.583) G_GAN: 0.550 G_GAN_Feat: 0.676 G_VGG: 1.632 D_real: 0.537 D_fake: 0.460 \n",
      "saving the latest model (epoch 162, total_steps 20000)\n",
      "End of epoch 162 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 163 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 164 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 165 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 166 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 167, iters: 56, time: 1.590) G_GAN: 0.548 G_GAN_Feat: 0.946 G_VGG: 1.813 D_real: 0.495 D_fake: 0.462 \n",
      "saving the latest model (epoch 167, total_steps 20640)\n",
      "End of epoch 167 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 168 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 169 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 170 / 200 \t Time Taken: 197 sec\n",
      "saving the model at the end of epoch 170, iters 21080\n",
      "End of epoch 171 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 172, iters: 76, time: 1.582) G_GAN: 0.553 G_GAN_Feat: 1.944 G_VGG: 1.443 D_real: 0.438 D_fake: 0.478 \n",
      "saving the latest model (epoch 172, total_steps 21280)\n",
      "End of epoch 172 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 173 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 174 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 175 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 176 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 177, iters: 96, time: 1.611) G_GAN: 0.554 G_GAN_Feat: 2.401 G_VGG: 1.731 D_real: 0.424 D_fake: 0.516 \n",
      "saving the latest model (epoch 177, total_steps 21920)\n",
      "End of epoch 177 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 178 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 179 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 180 / 200 \t Time Taken: 197 sec\n",
      "saving the model at the end of epoch 180, iters 22320\n",
      "End of epoch 181 / 200 \t Time Taken: 196 sec\n",
      "(epoch: 182, iters: 116, time: 1.575) G_GAN: 0.646 G_GAN_Feat: 2.192 G_VGG: 1.708 D_real: 0.445 D_fake: 0.411 \n",
      "saving the latest model (epoch 182, total_steps 22560)\n",
      "End of epoch 182 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 183 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 184 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 185 / 200 \t Time Taken: 197 sec\n",
      "End of epoch 186 / 200 \t Time Taken: 196 sec\n",
      "End of epoch 187 / 200 \t Time Taken: 197 sec\n",
      "(epoch: 188, iters: 12, time: 1.577) G_GAN: 0.750 G_GAN_Feat: 2.003 G_VGG: 1.463 D_real: 0.530 D_fake: 0.367 \n",
      "saving the latest model (epoch 188, total_steps 23200)\n",
      "End of epoch 188 / 200 \t Time Taken: 205 sec\n",
      "End of epoch 189 / 200 \t Time Taken: 331 sec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mainpath = os.getcwd()\n",
    "pix2pixhd_dir = Path(mainpath+'/src/pix2pixHD/')\n",
    "sys.path.append(str(pix2pixhd_dir))\n",
    "\n",
    "\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "from util.visualizer import Visualizer\n",
    "import src.config.train_opt as opt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# define training parameters\n",
    "def main():\n",
    "    iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "    data_loader = CreateDataLoader(opt)\n",
    "    dataset = data_loader.load_data()\n",
    "    dataset_size = len(data_loader)\n",
    "    print('#training images = %d' % dataset_size)\n",
    "\n",
    "    # note that we stopped at 120, and continued to train from 121\n",
    "    start_epoch, epoch_iter = 121, 0\n",
    "    total_steps = (start_epoch - 1) * dataset_size + epoch_iter\n",
    "    display_delta = total_steps % opt.display_freq\n",
    "    print_delta = total_steps % opt.print_freq\n",
    "    save_delta = total_steps % opt.save_latest_freq\n",
    "\n",
    "    model = create_model(opt)\n",
    "    model = model.cuda()\n",
    "    visualizer = Visualizer(opt)\n",
    "\n",
    "    for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        if epoch != start_epoch:\n",
    "            epoch_iter = epoch_iter % dataset_size\n",
    "        for i, data in enumerate(dataset, start=epoch_iter):\n",
    "            iter_start_time = time.time()\n",
    "            total_steps += opt.batchSize\n",
    "            epoch_iter += opt.batchSize\n",
    "\n",
    "            # whether to collect output images\n",
    "            save_fake = total_steps % opt.display_freq == display_delta\n",
    "\n",
    "            ############## Forward Pass ######################\n",
    "            losses, generated = model(Variable(data['label']), Variable(data['inst']),\n",
    "                                      Variable(data['image']), Variable(data['feat']), infer=save_fake)\n",
    "\n",
    "            # sum per device losses\n",
    "            losses = [torch.mean(x) if not isinstance(x, int) else x for x in losses]\n",
    "            loss_dict = dict(zip(model.loss_names, losses))\n",
    "\n",
    "            # calculate final loss scalar\n",
    "            loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "            loss_G = loss_dict['G_GAN'] + loss_dict.get('G_GAN_Feat', 0) + loss_dict.get('G_VGG', 0)\n",
    "\n",
    "            ############### Backward Pass ####################\n",
    "            # update generator weights\n",
    "            model.optimizer_G.zero_grad()\n",
    "            loss_G.backward()\n",
    "            model.optimizer_G.step()\n",
    "\n",
    "            # update discriminator weights\n",
    "            model.optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            model.optimizer_D.step()\n",
    "\n",
    "\n",
    "            ############## Display results and errors ##########\n",
    "            ### print out errors\n",
    "            if total_steps % opt.print_freq == print_delta:\n",
    "                errors = {k: v.data if not isinstance(v, int) else v for k, v in loss_dict.items()}\n",
    "                t = (time.time() - iter_start_time) / opt.batchSize\n",
    "                visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
    "                visualizer.plot_current_errors(errors, total_steps)\n",
    "\n",
    "            ### display output images\n",
    "            if save_fake:\n",
    "                visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\n",
    "                                       ('synthesized_image', util.tensor2im(generated.data[0])),\n",
    "                                       ('real_image', util.tensor2im(data['image'][0]))])\n",
    "                visualizer.display_current_results(visuals, epoch, total_steps)\n",
    "\n",
    "            ### save latest model\n",
    "            if total_steps % opt.save_latest_freq == save_delta:\n",
    "                print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "                model.save('latest')\n",
    "                np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "            if epoch_iter >= dataset_size:\n",
    "                break\n",
    "\n",
    "        # end of epoch\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "              (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "        ### save model for this epoch\n",
    "        if epoch % opt.save_epoch_freq == 0:\n",
    "            print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))\n",
    "            model.save('latest')\n",
    "            model.save(epoch)\n",
    "            np.savetxt(iter_path, (epoch + 1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "        ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "        if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "            model.update_fixed_params()\n",
    "\n",
    "        ### linearly decay learning rate after certain iterations\n",
    "        if epoch > opt.niter:\n",
    "            model.update_learning_rate()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
