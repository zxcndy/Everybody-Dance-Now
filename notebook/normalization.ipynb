{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [55:39<00:00,  6.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# this notebook is used to generate normalized images of the Target training dataset \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "target_img = cv2.imread('./data/target/train/train_label/00001.png')[:,:,0]\n",
    "target_img_rgb = cv2.imread('./data/target/train/train_img/00001.png')\n",
    "source_img = cv2.imread('./data/target/train/train_label/00001.png')[:,:,0]\n",
    "source_img_rgb = cv2.imread('./data/target/train/train_img/00001.png')\n",
    "\n",
    "path = './data/source/test_label_ori/'\n",
    "save_dir = Path('./data/source/')\n",
    "output = save_dir.joinpath('test_label')\n",
    "output.mkdir(exist_ok=True)\n",
    "head_dir = save_dir.joinpath('test_head')\n",
    "head_dir.mkdir(exist_ok=True)\n",
    "pose_dir = Path('./data/source/pose_source.npy')\n",
    "pose_cord = np.load(str(pose_dir))\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(target_img)\n",
    "plt.subplot(221)\n",
    "plt.imshow(target_img_rgb)\n",
    "plt.subplot(224)\n",
    "plt.imshow(source_img)\n",
    "plt.subplot(223)\n",
    "plt.imshow(source_img_rgb)\n",
    "plt.savefig('norm.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def get_scale(label_img):\n",
    "    any1 = label_img.any(axis=1)\n",
    "    linspace1 = np.arange(len(any1))\n",
    "    head_x, height = linspace1[list(any1)][0], len(linspace1[list(any1)])\n",
    "    any0 = label_img[head_x, :] != 0\n",
    "    linspace2 = np.arange(len(any0))\n",
    "    head_y = int(np.mean(linspace2[list(any0)]))\n",
    "    return (head_x,head_y),height\n",
    "\n",
    "target_head,target_height = get_scale(target_img)\n",
    "target_head_x = target_head[0]\n",
    "target_head_y = target_head[1]\n",
    "\n",
    "source_head,source_height = get_scale(source_img)\n",
    "\n",
    "\n",
    "new_head_pose = []\n",
    "\n",
    "for img_idx in tqdm(range(len(os.listdir(path)))):\n",
    "    img = cv2.imread(path+'{:05}.png'.format(img_idx))\n",
    "    source_rsize = cv2.resize(img,\n",
    "                              (int(img.shape[0] * target_height / source_height),\n",
    "                               int(img.shape[1] * target_height / source_height)))\n",
    "\n",
    "    source_pad = np.pad(source_rsize, ((1000, 1000), (1000, 1000),(0,0)), mode='edge')\n",
    "\n",
    "    source_head_rs, source_height_rs = get_scale(source_pad[:,:,0])\n",
    "    source_head_rs_x = source_head_rs[0]\n",
    "    source_head_rs_y = source_head_rs[1]\n",
    "\n",
    "    new_source = source_pad[\n",
    "                 (source_head_rs_x - target_head_x):(source_head_rs_x + (target_img.shape[0] - target_head_x)),\n",
    "                 int((source_pad.shape[1] - target_img.shape[1])/2):int((source_pad.shape[1]-(source_pad.shape[1] - target_img.shape[1])/2))\n",
    "                 ]\n",
    "    new_source_head, _ = get_scale(new_source[:,:,0])\n",
    "\n",
    "    source_head_x, source_head_y = source_head\n",
    "    source_cord_y, source_cord_x = pose_cord[0]\n",
    "\n",
    "    new_head_y = int(new_source_head[1] - (source_head_y - source_cord_y))\n",
    "    new_head_x = int(new_source_head[0] - (source_head_x - source_cord_x) * (target_height / source_height))\n",
    "\n",
    "    crop_size = 50\n",
    "    new_head_pose.append([new_head_y,new_head_x])\n",
    "    head = img[int(new_head_x - crop_size): int(new_head_x + crop_size),\n",
    "           int(new_head_y - crop_size): int(new_head_y + crop_size), :]\n",
    "    plt.imshow(head)\n",
    "    plt.savefig(str(head_dir.joinpath('pose_{}.jpg'.format(img_idx))))\n",
    "\n",
    "\n",
    "    cv2.imwrite(str(output) + '/{:05}.png'.format(img_idx),new_source)\n",
    "\n",
    "pose_cords_arr = np.array(new_head_pose, dtype=np.int)\n",
    "np.save(str((save_dir.joinpath('pose_source_norm.npy'))), pose_cords_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
